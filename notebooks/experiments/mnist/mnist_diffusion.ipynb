{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MNIST Diffusion - Let's get to real images!",
   "id": "19ddcef684f0ef14"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "import torch\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets, transforms\n\nfrom src.diffusion_playground.diffusion.noise_schedule import LinearNoiseSchedule\nfrom src.diffusion_playground.diffusion.training_utils import sample_xt\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load the MNIST-Dataset",
   "id": "2e65dafe7983aa3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Load MNIST dataset directly as a tensor\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\nmnist_dataset = datasets.MNIST(root=\"data\", train=True, transform=transform, download=True)\n\n# Extract all images into a single tensor\nmnist_data = torch.stack([mnist_dataset[i][0] for i in range(len(mnist_dataset))])\nmnist_labels = torch.tensor([mnist_dataset[i][1] for i in range(len(mnist_dataset))])\n\nprint(f\"Dataset shape: {mnist_data.shape}\")\nprint(f\"Labels shape: {mnist_labels.shape}\")\nprint(f\"Input shape per image: (1, 28, 28)\")",
   "id": "d0cfbf1134308598",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Explore the Dataset",
   "id": "dbab24833afb5c2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Pick a random sample to visualize\nsample_idx = 5\n\nprint(f\"Sample label: {mnist_labels[sample_idx].item()}\")\n\nplt.imshow(mnist_data[sample_idx][0], cmap=\"gray\")\nplt.title(f\"Sample MNIST Digit: {mnist_labels[sample_idx].item()}\")\nplt.axis(\"off\")\nplt.show()",
   "id": "f5b5e520c881147c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Forward Diffusion on MNIST",
   "id": "fcfcb1ecfb5a92bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Create NoiseSchedule\nschedule = LinearNoiseSchedule(time_steps=1_000)\n\n# Use a batch from our data for visualization\nx0_batch = mnist_data[:128]  # Take first 128 samples\n\ntime_steps = [0, 50, 200, 500, 999]\n\nplt.figure(figsize=(15, 3))\nfor i, t in enumerate(time_steps):\n    # Create a batch of time steps (one per sample in the batch)\n    t_tensor = torch.full((x0_batch.shape[0],), t)\n    xt, _, _ = sample_xt(x0_batch, schedule, t=t_tensor)\n\n    plt.subplot(1, len(time_steps), i + 1)\n    plt.imshow(xt[0, 0].cpu(), cmap=\"gray\")\n    plt.title(f\"t={t}\")\n    plt.axis(\"off\")\n\nplt.show()",
   "id": "fc3ca33f3693a685",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ru0gi46vzz8",
   "source": "## Train the CNN Denoiser\n\nNow let's train a UNet-style CNN to learn the reverse diffusion process on MNIST! Unlike the simple MLP we used for the toy moons dataset, this CNN architecture uses:\n\n- **Convolutional layers** to preserve spatial structure\n- **Encoder-decoder architecture** (UNet) with skip connections\n- **Sinusoidal time embeddings** for better time conditioning\n\nThe beauty of our generic training pipeline is that we use the **exact same `train_denoiser` function** - only the model architecture changes!\n\n**Note**: Training on images takes longer than the toy dataset. For a full training run, you might want to train for 50,000-100,000 epochs. For quick testing, we'll use fewer epochs here.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "tou3oeb1mc9",
   "source": "from src.diffusion_playground.models import CNNDenoiser\nfrom src.diffusion_playground.training.denoiser_trainer import train_denoiser\n\n# Data is already loaded as mnist_data tensor - no need to collect from DataLoader!\nprint(f\"Training data shape: {mnist_data.shape}\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the CNN denoiser model\n",
    "model = CNNDenoiser(in_channels=1, base_channels=32, time_emb_dim=128)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(model)"
   ],
   "id": "df03c79066528dc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model (using the same generic training function!)\n",
    "# Note: Adjust epochs based on your needs (50k-100k for full training, 10k for quick test)\n",
    "train_denoiser(\n",
    "    model=model,\n",
    "    data=mnist_data,\n",
    "    noise_schedule=schedule,\n",
    "    epochs=10,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    checkpoint_dir=\"checkpoints/mnist_cnn\",\n",
    "    save_every=3\n",
    ")"
   ],
   "id": "84f5d50992f88d61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Test the Reverse Diffusion Process\n",
    "\n",
    "Let's test our trained model by performing the reverse diffusion process - generating images from pure noise! Even with minimal training, this will verify that all our interfaces work correctly together."
   ],
   "id": "b32dbae0ea60a3ca"
  },
  {
   "cell_type": "code",
   "id": "ebw8fa1nhuj",
   "source": [
    "from src.diffusion_playground.training.denoiser_trainer import load_checkpoint\n",
    "\n",
    "# Always load the best checkpoint for evaluation\n",
    "# This allows running the evaluation independently without training first\n",
    "cp_name = \"checkpoint_epoch_1000.pt\"\n",
    "checkpoint_path = f\"checkpoints/mnist_cnn/{cp_name}\"\n",
    "\n",
    "# Create a fresh model instance (in case we're running this cell standalone)\n",
    "model = CNNDenoiser(in_channels=1, base_channels=32, time_emb_dim=128)\n",
    "model.to(device)\n",
    "\n",
    "# Load the best checkpoint\n",
    "checkpoint_info = load_checkpoint(model, checkpoint_path, device=device)\n",
    "print(f\"Loaded model trained for {checkpoint_info['epoch']} epochs\")\n",
    "print(f\"Best training loss: {checkpoint_info['loss']:.6f}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Setup for generation\nmodel.eval()\nnum_samples = 16\ntime_steps = schedule.time_steps\n\n# Start from pure noise\nxt = torch.randn(num_samples, 1, 28, 28).to(device)\n\nprint(f\"Starting reverse diffusion from noise shape: {xt.shape}\")\n\n# Reverse diffusion loop with STOCHASTIC sampling (adds noise for diversity!)\nwith torch.no_grad():\n    for t in reversed(range(1, time_steps + 1)):\n        # Create time tensor for all samples\n        t_tensor = torch.full((num_samples,), t, device=device, dtype=torch.long)\n\n        # Predict the noise\n        pred_noise = model(xt, t_tensor)\n\n        # Get schedule parameters\n        beta_t = schedule.betas[t - 1]\n        alpha_t = schedule.alphas[t - 1]\n        alpha_bar_t = schedule.alpha_bars[t - 1]\n\n        # Compute the mean of the reverse distribution\n        mean = (xt - beta_t / torch.sqrt(1 - alpha_bar_t) * pred_noise) / torch.sqrt(alpha_t)\n\n        # Add noise (STOCHASTIC sampling for diversity!)\n        if t > 1:\n            # Add Gaussian noise scaled by beta\n            noise = torch.randn_like(xt)\n            sigma_t = torch.sqrt(beta_t)\n            x_prev = mean + sigma_t * noise\n        else:\n            # No noise at the final step\n            x_prev = mean\n\n        # Update xt\n        xt = x_prev\n\n        # Print progress every 100 steps\n        if t % 100 == 0:\n            print(f\"  Step {time_steps - t + 1}/{time_steps} (t={t})\")\n\nprint(\"Reverse diffusion complete!\")\n\n# Visualize generated samples with checkpoint information\nfig, axes = plt.subplots(4, 4, figsize=(8, 8))\nfor idx, ax in enumerate(axes.flat):\n    ax.imshow(xt[idx, 0].cpu(), cmap=\"gray\")\n    ax.axis(\"off\")\n\n# Create informative title with checkpoint details\ntitle = f\"Generated MNIST Digits - {cp_name}\\n\"\ntitle += f\"Epoch: {checkpoint_info['epoch']} | Loss: {checkpoint_info['loss']:.6f}\"\nplt.suptitle(title, fontsize=12, fontweight='bold')\nplt.tight_layout()\nplt.show()",
   "id": "41570102c94ba001",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7byvpmuii26",
   "source": "## Generate Documentation Visualizations\n\nCreate and save visualizations for multiple checkpoints to use in the README documentation.",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path(\"../../../docs/mnist-cnn\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Checkpoints to visualize\n",
    "checkpoint_epochs = [1000, 10000, 50000, 79000]\n",
    "\n",
    "for epoch in checkpoint_epochs:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Processing checkpoint: epoch {epoch}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Define checkpoint path\n",
    "    cp_name = f\"checkpoint_epoch_{epoch}.pt\"\n",
    "    checkpoint_path = f\"checkpoints/mnist_cnn/{cp_name}\"\n",
    "\n",
    "    # Check if checkpoint exists\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"⚠️  Checkpoint not found: {checkpoint_path}\")\n",
    "        print(f\"   Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Load checkpoint\n",
    "    model = CNNDenoiser(in_channels=1, base_channels=32, time_emb_dim=128)\n",
    "    model.to(device)\n",
    "    checkpoint_info = load_checkpoint(model, checkpoint_path, device=device)\n",
    "    model.eval()\n",
    "\n",
    "    # Generate samples (3x3 = 9 samples for documentation)\n",
    "    num_samples = 9\n",
    "    xt = torch.randn(num_samples, 1, 28, 28).to(device)\n",
    "\n",
    "    print(f\"Generating {num_samples} samples...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for t in reversed(range(1, schedule.time_steps + 1)):\n",
    "            t_tensor = torch.full((num_samples,), t, device=device, dtype=torch.long)\n",
    "            pred_noise = model(xt, t_tensor)\n",
    "\n",
    "            beta_t = schedule.betas[t - 1]\n",
    "            alpha_t = schedule.alphas[t - 1]\n",
    "            alpha_bar_t = schedule.alpha_bars[t - 1]\n",
    "\n",
    "            mean = (xt - beta_t / torch.sqrt(1 - alpha_bar_t) * pred_noise) / torch.sqrt(alpha_t)\n",
    "\n",
    "            if t > 1:\n",
    "                noise = torch.randn_like(xt)\n",
    "                sigma_t = torch.sqrt(beta_t)\n",
    "                xt = mean + sigma_t * noise\n",
    "            else:\n",
    "                xt = mean\n",
    "\n",
    "    # Create visualization (3x3 grid)\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        ax.imshow(xt[idx, 0].cpu(), cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Add informative title\n",
    "    title = f\"Generated MNIST Digits - {cp_name}\\n\"\n",
    "    title += f\"Epoch: {checkpoint_info['epoch']} | Loss: {checkpoint_info['loss']:.6f}\"\n",
    "    plt.suptitle(title, fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    output_filename = f\"generated_samples_epoch_{epoch}.png\"\n",
    "    output_path = output_dir / output_filename\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Saved visualization to: {output_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"✓ All visualizations completed!\")\n",
    "print(f\"{'=' * 60}\")"
   ],
   "id": "3c1f6c6df7e1709d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7e3f43ba235c21da",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
